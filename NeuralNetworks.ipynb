{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, size_list, dropout = False, dropoutProb = 0.1, batchNorm = False):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        self.size_list = size_list\n",
    "        for i in range(len(size_list) - 2):\n",
    "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            if batchNorm:\n",
    "                layers.append(nn.BatchNorm1d(size_list[i+1]))\n",
    "                \n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(p = dropoutProb))\n",
    "            \n",
    "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
    "        \n",
    "        # Unpack the list\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, size_list):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=size_list[0],\n",
    "            hidden_size=size_list[1],         # rnn hidden unit\n",
    "            num_layers=len(size_list)-2,           # number of rnn layer\n",
    "            )\n",
    "\n",
    "        self.out = nn.Linear(size_list[-2], size_list[-1])\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "\n",
    "def train_epoch(model, optimizer, X_train, y_train, criterion):\n",
    "    model.train()\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    optimizer.zero_grad()  \n",
    "\n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    running_loss = loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    #print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    return running_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer can be 'SGD', 'RMSprop', 'ADAM', \n",
    "def nnTrain(X_train, y_train, size_list, dropout = False, dropoutProb = 0.1, batchNorm = False, \n",
    "                optimizer = 'SGD', lr = 0.01, n_epochs = 100, LSTM = False):   \n",
    "\n",
    "    X_train = torch.autograd.Variable(torch.Tensor(X_train.values.astype(float)))\n",
    "    y_train = torch.autograd.Variable(torch.Tensor(y_train.values.astype(float)))\n",
    "    \n",
    "    if LSTM == True:\n",
    "        X_train = X_train.view(-1, X_train.shape[0], X_train.shape[1])\n",
    "        model = RNN(size_list)\n",
    "    else:\n",
    "        model = MLP(size_list, dropout, dropoutProb, batchNorm)\n",
    "    \n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "    if optimizer == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr = lr)\n",
    "    if optimizer == 'ADAM':\n",
    "        optimizer = optim.ADAM(model.parameters(), lr = lr)\n",
    "    \n",
    "    Train_loss = []\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        train_loss = train_epoch(model, optimizer, X_train, y_train, criterion)\n",
    "        Train_loss.append(train_loss)\n",
    "    \n",
    "    return model, Train_loss\n",
    "\n",
    "\n",
    "def nnTest(model, X_test, y_test):\n",
    "    X_test = torch.autograd.Variable(torch.Tensor(X_test.values.astype(float)))\n",
    "    y_test = torch.autograd.Variable(torch.Tensor(y_test.values.astype(float)))\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if hasattr(model, 'rnn'):\n",
    "        X_test = X_test.view(-1, X_test.shape[0], X_test.shape[1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()        \n",
    "\n",
    "        outputs = model(X_test)\n",
    "\n",
    "        loss = criterion(outputs, y_test).detach()\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        return running_loss\n",
    "    \n",
    "def nnPredict(model, X_test):\n",
    "    X_test = torch.autograd.Variable(torch.Tensor(X_test.values.astype(float)))\n",
    "    \n",
    "    if hasattr(model, 'rnn'):\n",
    "        X_test = X_test.view(-1, X_test.shape[0], X_test.shape[1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()        \n",
    "        outputs = model(X_test)\n",
    "    return np.array(outputs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1017: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n",
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CON.DE']\n",
      "['RWE.DE']\n",
      "['DTE.DE']\n",
      "['BEI.DE']\n",
      "['HEI.DE']\n",
      "['LIN.DE']\n",
      "['FRE.DE']\n",
      "['ADS.DE']\n",
      "['FME.DE']\n",
      "['MRK.DE']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pandas_datareader as web\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_network as npy\n",
    "import os \n",
    "import sys\n",
    "\n",
    "\n",
    "def get_random_tickers(n, ticklist):\n",
    "    if n >len(ticklist):\n",
    "        raise Exception('n is bigger than ticklist')\n",
    "    return np.random.choice(ticklist, size=n, replace=False)\n",
    "RSVE = []\n",
    "\n",
    "\n",
    "# Our initial ticklist\n",
    "ticklist = ['ADS.DE', 'ALV.DE', 'BAS.DE', 'BEI.DE', 'BMW.DE', 'CON.DE', 'DAI.DE', 'DBK.DE', 'DTE.DE', 'EOAN.DE', 'FME.DE',\n",
    " 'FRE.DE', 'HEI.DE', 'HEN3.DE', 'LHA.DE', 'LIN.DE', 'MRK.DE', 'MUV2.DE', 'RWE.DE', 'SAP.DE', 'SIE.DE', 'TKA.DE', 'VOW3.DE']\n",
    "\n",
    "# The 7 tickers chosen randomly from this ticklist\n",
    "\n",
    "ticklist = get_random_tickers(10, ticklist)\n",
    "#ticklist = ['LIN.DE', 'HEN3.DE', 'DAI.DE', 'FME.DE', 'MUV2.DE', 'SIE.DE', 'DBK.DE']\n",
    "ticklist = ['CON.DE', 'RWE.DE', 'DTE.DE', 'BEI.DE', 'HEI.DE', 'LIN.DE','FRE.DE', 'ADS.DE','FME.DE','MRK.DE']\n",
    "\n",
    "tickdict = dict(zip(ticklist, range(1,len(ticklist)+1)))\n",
    "\n",
    "## Paramteres\n",
    "d0 = '2001-01-01' # begining of the waiting period\n",
    "d1 = '2004-01-01' # end of the CV period - beg\n",
    "d2 = '2006-01-01' # begining of the test period\n",
    "d3 = '2008-01-01' # end of the test period\n",
    "\n",
    "dcv1 = '2004-01-01'\n",
    "dcv2 = '2005-01-01'\n",
    "\n",
    "\n",
    "### Parameters\n",
    "norm=True\n",
    "cv_nlayers=True\n",
    "cv_nneurones = False\n",
    "lbd = 0.2 # history weight metric\n",
    "alpha = 0.09 # risk management metric\n",
    "cst = 10 #weight metric\n",
    "delta = 0.91\n",
    "\n",
    "\n",
    "\n",
    "nneurones = 10\n",
    "nlayers = 4\n",
    "drp = False\n",
    "drpProb = 0.1\n",
    "batch = False \n",
    "opt = 'SGD'\n",
    "learning_rate = 0.01\n",
    "n_epochs = 400\n",
    "\n",
    "\n",
    "\n",
    "# Generate the X matrix and Y matrix and make them have only trading days\n",
    "\n",
    "dtes = pd.read_csv('trading_days.csv', index_col=0)\n",
    "tempdt = dtes.copy()\n",
    "tempdt.set_index('Buy', drop=True, inplace=True)\n",
    "tempdt.index = pd.to_datetime(tempdt.index)\n",
    "\n",
    "Y = []\n",
    "X = pd.DataFrame(columns=['Date', 'EMA10', 'EMA16', 'EMA22', 'SMA10', 'SMA16', 'SMA22','ValueAtRisk', \n",
    "                       'Bollu20', 'Bollu26', 'Bollu32', 'Bolld20', 'Bolld26', 'Bolld32',\n",
    "                       'Mom12', 'Mom18', 'Mom24', 'ACC12', 'ACC18', 'ACC24', 'ROC10', 'ROC16',\n",
    "                       'ROC22', 'MACD1812', 'MACD2412','MACD3012', 'MACDS18129', 'MACDS24129', 'MACDS30129', \n",
    "                       'RSI8', 'RSI14', 'RSI20', 'OBV', 'CHV1010', 'CHV1016', 'CHV1022',\n",
    "                       'FastK12', 'FastD12', 'FastK18', 'SlowK12', 'FastD18', 'SlowD12',\n",
    "                       'FastK24', 'SlowK18', 'FastD24', 'SlowD18', 'SlowK24', 'SlowD24',\n",
    "                       'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', \n",
    "                       'Ticker','Month', 'DAX', 'ADL', 'Type1', 'Type2', 'Type3', 'Y'])\n",
    "\n",
    "dax = web.get_data_yahoo('^GDAXI', start=d0, end=d3)\n",
    "prices = pd.DataFrame(columns=['Ticker', 'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Date'])\n",
    "\n",
    "\n",
    "for tick in ticklist:\n",
    "    if norm:\n",
    "        temp = pd.read_csv('tickDataNorm/'+ str(delta).replace('.', '') +'/' + tick.replace('.', '') +'.csv', index_col=0)\n",
    "    else:\n",
    "        temp = pd.read_csv('tickData/'+ str(delta).replace('.', '') +'/' + tick.replace('.', '') +'.csv', index_col=0)\n",
    "    prices = pd.concat([prices, temp.loc[:, ['Ticker', 'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Date']]],axis=0, ignore_index=True, sort=False,copy=True)\n",
    "    # Select dates around events\n",
    "    temp.set_index('Date', inplace=True, drop=True)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    B = temp.loc[pd.to_datetime(dtes.Buy), 'Close']\n",
    "    S = temp.loc[pd.to_datetime(dtes.Sell), 'Close']\n",
    "    temp = temp.loc[tempdt.index, :]\n",
    "    temp['Y'] = 100*(S.values-B.values)/B.values\n",
    "    \n",
    "    mask = np.logical_not(np.isnan(temp['Y'].values))\n",
    "    temp = temp.loc[mask, :]\n",
    "    if norm:\n",
    "        temp.loc[:,'High'] = temp.loc[:,'Norm_High']\n",
    "        temp.loc[:,'Low'] = temp.loc[:,'Norm_Low']\n",
    "        temp.loc[:,'Open'] = temp.loc[:,'Norm_Open']\n",
    "        temp.loc[:,'Close'] = temp.loc[:,'Norm_Close']\n",
    "        temp.loc[:,'AdjClose'] = temp.loc[:,'Norm_AdjClose']\n",
    "    #temp = temp.loc[pd.to_datetime(dtes.Buy), :]\n",
    "    temp['Month'] = temp.index.month\n",
    "    temp['Date'] = temp.index\n",
    "    temp['DAX'] = dax.loc[temp.index, 'Adj Close']\n",
    "    temp.loc[:,'Type'] = tempdt.loc[mask, 'Type'].values\n",
    "    temp = temp.loc[:,['Date', 'EMA10', 'EMA16', 'EMA22', 'SMA10', 'SMA16', 'SMA22','ValueAtRisk', \n",
    "                       'Bollu20', 'Bollu26', 'Bollu32', 'Bolld20', 'Bolld26', 'Bolld32',\n",
    "                       'Mom12', 'Mom18', 'Mom24', 'ACC12', 'ACC18', 'ACC24', 'ROC10', 'ROC16',\n",
    "                       'ROC22', 'MACD1812', 'MACD2412','MACD3012', 'MACDS18129', 'MACDS24129', 'MACDS30129', \n",
    "                       'RSI8', 'RSI14', 'RSI20', 'OBV', 'CHV1010', 'CHV1016', 'CHV1022',\n",
    "                       'FastK12', 'FastD12', 'FastK18', 'SlowK12', 'FastD18', 'SlowD12',\n",
    "                       'FastK24', 'SlowK18', 'FastD24', 'SlowD18', 'SlowK24', 'SlowD24',\n",
    "                       'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Ticker',\n",
    "                       'Month', 'DAX', 'ADL','Type', 'Y']]\n",
    "    \n",
    "\n",
    "    temp['Type1'] = (temp.loc[:,'Type'].values == 1)*1\n",
    "    temp['Type2'] = (temp.loc[:,'Type'].values == 2)*1\n",
    "    temp['Type3'] = (temp.loc[:,'Type'].values == 3)*1\n",
    "    temp = temp.loc[:,['Date', 'EMA10', 'EMA16', 'EMA22', 'SMA10', 'SMA16', 'SMA22','ValueAtRisk', \n",
    "                       'Bollu20', 'Bollu26', 'Bollu32', 'Bolld20', 'Bolld26', 'Bolld32',\n",
    "                       'Mom12', 'Mom18', 'Mom24', 'ACC12', 'ACC18', 'ACC24', 'ROC10', 'ROC16',\n",
    "                       'ROC22', 'MACD1812', 'MACD2412','MACD3012', 'MACDS18129', 'MACDS24129', 'MACDS30129', \n",
    "                       'RSI8', 'RSI14', 'RSI20', 'OBV', 'CHV1010', 'CHV1016', 'CHV1022',\n",
    "                       'FastK12', 'FastD12', 'FastK18', 'SlowK12', 'FastD18', 'SlowD12',\n",
    "                       'FastK24', 'SlowK18', 'FastD24', 'SlowD18', 'SlowK24', 'SlowD24',\n",
    "                       'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', \n",
    "                       'Ticker','Month', 'DAX', 'ADL', 'Type1', 'Type2', 'Type3', 'Y']]\n",
    "    print(temp.Ticker.unique())\n",
    "    X = pd.concat([X, temp], axis=0, ignore_index=True, copy=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = X.Ticker.unique()\n",
    "tickdict = dict(zip(T, range(len(T))))\n",
    "for tick in T:\n",
    "    X.loc[X.Ticker==tick,'Ticker']= tickdict[tick]\n",
    "    \n",
    "X.sort_values(by=['Date', 'Ticker'], inplace=True)\n",
    "X.set_index('Date', drop=True, inplace=True)\n",
    "X = X.loc[((X.index>=pd.to_datetime(d0)) & (X.index<=pd.to_datetime(d3))), :]\n",
    "\n",
    "## X is generated\n",
    "\n",
    "## Normalizing features\n",
    "C = ['EMA10', 'EMA16', 'EMA22', 'SMA10', 'SMA16', 'SMA22','ValueAtRisk', \n",
    "                       'Bollu20', 'Bollu26', 'Bollu32', 'Bolld20', 'Bolld26', 'Bolld32',\n",
    "                       'Mom12', 'Mom18', 'Mom24', 'ACC12', 'ACC18', 'ACC24', 'ROC10', 'ROC16',\n",
    "                       'ROC22', 'MACD1812', 'MACD2412','MACD3012', 'MACDS18129', 'MACDS24129', 'MACDS30129', \n",
    "                       'RSI8', 'RSI14', 'RSI20', 'OBV', 'CHV1010', 'CHV1016', 'CHV1022',\n",
    "                       'FastK12', 'FastD12', 'FastK18', 'SlowK12', 'FastD18', 'SlowD12',\n",
    "                       'FastK24', 'SlowK18', 'FastD24', 'SlowD18', 'SlowK24', 'SlowD24',\n",
    "                       'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Ticker',\n",
    "                       'Month', 'DAX', 'ADL','Type1', 'Type2', 'Type3']\n",
    "\n",
    "Cnorm = ['EMA10', 'EMA16', 'EMA22', 'SMA10', 'SMA16', 'SMA22','ValueAtRisk', \n",
    "                       'Bollu20', 'Bollu26', 'Bollu32', 'Bolld20', 'Bolld26', 'Bolld32',\n",
    "                       'Mom12', 'Mom18', 'Mom24', 'ACC12', 'ACC18', 'ACC24', 'ROC10', 'ROC16',\n",
    "                       'ROC22', 'MACD1812', 'MACD2412','MACD3012', 'MACDS18129', 'MACDS24129', 'MACDS30129', \n",
    "                       'RSI8', 'RSI14', 'RSI20', 'OBV', 'CHV1010', 'CHV1016', 'CHV1022',\n",
    "                       'FastK12', 'FastD12', 'FastK18', 'SlowK12', 'FastD18', 'SlowD12',\n",
    "                       'FastK24', 'SlowK18', 'FastD24', 'SlowD18', 'SlowK24', 'SlowD24',\n",
    "                       'High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose',\n",
    "                       'Month', 'DAX', 'ADL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "q1, q2 = X['Y'].quantile(0.98), X['Y'].quantile(0.02)\n",
    "X = X[(X['Y'] < q1) & (X['Y'] > q2)]\n",
    "\n",
    "## Normalization\n",
    "Xtrain1 = X.loc[((X.index>pd.to_datetime(d0)) & (X.index<=pd.to_datetime(d1))), C].copy()\n",
    "Ytrain1 = X.loc[((X.index>pd.to_datetime(d0)) & (X.index<=pd.to_datetime(d1))), 'Y'].copy()\n",
    "\n",
    "Xmean = np.mean(Xtrain1.loc[:,Cnorm])\n",
    "Xstdev = np.std(Xtrain1.loc[:,Cnorm])\n",
    "\n",
    "\n",
    "\n",
    "X_old = X.copy()\n",
    "X.loc[:, Cnorm] = (X.loc[:, Cnorm]-Xmean)/(Xstdev)\n",
    "\n",
    "Xcv1 = X.loc[((X.index>pd.to_datetime(d0)) & (X.index<=pd.to_datetime(d1))), C].copy()\n",
    "Ycv1 = X.loc[((X.index>pd.to_datetime(d0)) & (X.index<=pd.to_datetime(d1))), 'Y'].copy()\n",
    "Xtrain1 = X.loc[((X.index>pd.to_datetime(d1)) & (X.index<=pd.to_datetime(d2))), C].copy()\n",
    "Ytrain1 = X.loc[((X.index>pd.to_datetime(d1)) & (X.index<=pd.to_datetime(d2))), 'Y'].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drp = False\n",
    "drpProb = 0.1\n",
    "batch = False\n",
    "optimizer = 'SGD'\n",
    "learning_rate = 0.02\n",
    "n_epochs = 1000\n",
    "\n",
    "\n",
    "layer_ls = list(range(1,8))\n",
    "neuron_ls = list(range(1,16))\n",
    "\n",
    "\n",
    "loss_array = np.zeros((len(layer_ls), len(neuron_ls)))\n",
    "for nlayers in layer_ls:\n",
    "    for nneurons in neuron_ls:\n",
    "        ls = [nneurons]*nlayers\n",
    "        ls = np.insert(ls, 0, Xcv1.shape[1]).tolist()\n",
    "        ls.append(1)\n",
    "        nnt, err = npy.nnTrain(Xtrain1, Ytrain1, ls, drp, drpProb, batch, opt, learning_rate, n_epochs) \n",
    "        loss_array[nlayers-1,nneurons-1]  = npy.nnTest(nnt, Xcv1, Ycv1)        \n",
    "        plt.plot(err)        \n",
    "\n",
    "plt.xlabel('Reps')\n",
    "plt.ylabel('Losses')\n",
    "plt.title('Computed train losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see for each network, the loss converges before 1000 training epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n",
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py:504: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "loss_df = pd.DataFrame(loss_array, index=layer_ls, columns=neuron_ls)\n",
    "loss_df\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "neuron_array, layer_array = np.meshgrid(neuron_ls, layer_ls)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(layer_array, neuron_array, loss_array, cmap=cm.coolwarm)\n",
    "ax.set_xlabel('layers')\n",
    "ax.set_ylabel('neurons')\n",
    "ax.set_zlabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.787170</td>\n",
       "      <td>3.783708</td>\n",
       "      <td>3.784104</td>\n",
       "      <td>3.792151</td>\n",
       "      <td>3.799195</td>\n",
       "      <td>3.779632</td>\n",
       "      <td>3.801437</td>\n",
       "      <td>3.792228</td>\n",
       "      <td>3.782649</td>\n",
       "      <td>3.792413</td>\n",
       "      <td>3.787357</td>\n",
       "      <td>3.799966</td>\n",
       "      <td>3.786602</td>\n",
       "      <td>3.786769</td>\n",
       "      <td>3.819743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.782095</td>\n",
       "      <td>3.786403</td>\n",
       "      <td>3.784986</td>\n",
       "      <td>3.782626</td>\n",
       "      <td>3.787333</td>\n",
       "      <td>3.779355</td>\n",
       "      <td>3.782468</td>\n",
       "      <td>3.780941</td>\n",
       "      <td>3.784262</td>\n",
       "      <td>3.786437</td>\n",
       "      <td>3.781793</td>\n",
       "      <td>3.781092</td>\n",
       "      <td>3.794440</td>\n",
       "      <td>3.785257</td>\n",
       "      <td>3.782782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.783604</td>\n",
       "      <td>3.781651</td>\n",
       "      <td>3.778811</td>\n",
       "      <td>3.787477</td>\n",
       "      <td>3.782374</td>\n",
       "      <td>3.784207</td>\n",
       "      <td>3.783889</td>\n",
       "      <td>3.787074</td>\n",
       "      <td>3.783546</td>\n",
       "      <td>3.784503</td>\n",
       "      <td>3.783219</td>\n",
       "      <td>3.783018</td>\n",
       "      <td>3.779996</td>\n",
       "      <td>3.781688</td>\n",
       "      <td>3.780912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.781044</td>\n",
       "      <td>3.783406</td>\n",
       "      <td>3.783622</td>\n",
       "      <td>3.780870</td>\n",
       "      <td>3.782206</td>\n",
       "      <td>3.781634</td>\n",
       "      <td>3.782268</td>\n",
       "      <td>3.782923</td>\n",
       "      <td>3.782773</td>\n",
       "      <td>3.781934</td>\n",
       "      <td>3.782005</td>\n",
       "      <td>3.778643</td>\n",
       "      <td>3.779603</td>\n",
       "      <td>3.781857</td>\n",
       "      <td>3.782268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.782140</td>\n",
       "      <td>3.782181</td>\n",
       "      <td>3.782233</td>\n",
       "      <td>3.782202</td>\n",
       "      <td>3.782421</td>\n",
       "      <td>3.782404</td>\n",
       "      <td>3.782040</td>\n",
       "      <td>3.782186</td>\n",
       "      <td>3.782991</td>\n",
       "      <td>3.781669</td>\n",
       "      <td>3.781499</td>\n",
       "      <td>3.782235</td>\n",
       "      <td>3.782433</td>\n",
       "      <td>3.782196</td>\n",
       "      <td>3.782627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.781859</td>\n",
       "      <td>3.782780</td>\n",
       "      <td>3.782510</td>\n",
       "      <td>3.782500</td>\n",
       "      <td>3.782142</td>\n",
       "      <td>3.782784</td>\n",
       "      <td>3.782862</td>\n",
       "      <td>3.781742</td>\n",
       "      <td>3.782341</td>\n",
       "      <td>3.782380</td>\n",
       "      <td>3.782853</td>\n",
       "      <td>3.781934</td>\n",
       "      <td>3.781837</td>\n",
       "      <td>3.782511</td>\n",
       "      <td>3.782392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.782469</td>\n",
       "      <td>3.782198</td>\n",
       "      <td>3.782161</td>\n",
       "      <td>3.782535</td>\n",
       "      <td>3.782349</td>\n",
       "      <td>3.780908</td>\n",
       "      <td>3.782640</td>\n",
       "      <td>3.781985</td>\n",
       "      <td>3.782113</td>\n",
       "      <td>3.782637</td>\n",
       "      <td>3.782498</td>\n",
       "      <td>3.782314</td>\n",
       "      <td>3.782379</td>\n",
       "      <td>3.782581</td>\n",
       "      <td>3.782252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7   \\\n",
       "1  3.787170  3.783708  3.784104  3.792151  3.799195  3.779632  3.801437   \n",
       "2  3.782095  3.786403  3.784986  3.782626  3.787333  3.779355  3.782468   \n",
       "3  3.783604  3.781651  3.778811  3.787477  3.782374  3.784207  3.783889   \n",
       "4  3.781044  3.783406  3.783622  3.780870  3.782206  3.781634  3.782268   \n",
       "5  3.782140  3.782181  3.782233  3.782202  3.782421  3.782404  3.782040   \n",
       "6  3.781859  3.782780  3.782510  3.782500  3.782142  3.782784  3.782862   \n",
       "7  3.782469  3.782198  3.782161  3.782535  3.782349  3.780908  3.782640   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "1  3.792228  3.782649  3.792413  3.787357  3.799966  3.786602  3.786769   \n",
       "2  3.780941  3.784262  3.786437  3.781793  3.781092  3.794440  3.785257   \n",
       "3  3.787074  3.783546  3.784503  3.783219  3.783018  3.779996  3.781688   \n",
       "4  3.782923  3.782773  3.781934  3.782005  3.778643  3.779603  3.781857   \n",
       "5  3.782186  3.782991  3.781669  3.781499  3.782235  3.782433  3.782196   \n",
       "6  3.781742  3.782341  3.782380  3.782853  3.781934  3.781837  3.782511   \n",
       "7  3.781985  3.782113  3.782637  3.782498  3.782314  3.782379  3.782581   \n",
       "\n",
       "         15  \n",
       "1  3.819743  \n",
       "2  3.782782  \n",
       "3  3.780912  \n",
       "4  3.782268  \n",
       "5  3.782627  \n",
       "6  3.782392  \n",
       "7  3.782252  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When increasing nlayers and nneurons do not improve the performance too much, we choose not to add too much complexity to the model. The selected number of layers is 4, and number of neurons per layer is 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the train errors converge on a level far lower the testing error. This is a sign of overfitting, so we try dropout. In addition, the optimization may fall into local minimum, so we try RMSprop and Adam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To control the covariate shift in the financial data, we also apply batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_dist = {'drp_ls': [True, False],\n",
    "             'drpProb_ls': [0.3, 0.5 ,0.6, 0.7, 0.9],\n",
    "             'batch_ls': [True, False],\n",
    "             'optimizer_ls': ['SGD', 'RMSprop', 'ADAM'],\n",
    "             'layer_ls': [2,4,6],\n",
    "              'neuron_ls': [5,7,9,11]}\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.02\n",
    "n_epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "result = {}\n",
    "result2 = {}\n",
    "for drp in param_dist['drp_ls']:\n",
    "    for drpProb in param_dist['drpProb_ls']:\n",
    "        for batch in param_dist['batch_ls']:\n",
    "            for optimizer in param_dist['optimizer_ls']:\n",
    "                for nlayer in param_dist['layer_ls']:\n",
    "                    for nneurons in param_dist['neuron_ls']:\n",
    "                        ls = [nneurons]*nlayers\n",
    "                        ls = np.insert(ls, 0, Xcv1.shape[1]).tolist()\n",
    "                        ls.append(1)\n",
    "                        nnt, err = npy.nnTrain(Xtrain1, Ytrain1, ls, drp, drpProb, batch, opt, learning_rate, n_epochs) \n",
    "                        string = 'drp:' + str(drp) + ' dropProb:' + str(drpProb) + ' batch:' + str(batch)\\\n",
    "                        + ' optimizer:' + str(optimizer) + ' nlayer:' + str(nlayer) + ' nneurons:' + str(nneurons)\n",
    "                        result[string]  = npy.nnTest(nnt, Xcv1, Ycv1) \n",
    "                        result2[string] = err\n",
    "                        if sum(err>20) == 0:\n",
    "                            plt.plot(err)\n",
    "                        print(string, result[string])\n",
    "\n",
    "plt.xlabel('Reps')\n",
    "plt.ylabel('Losses')\n",
    "plt.title('Computed train losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7836990356445312,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7827348709106445,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7811200618743896,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.7811152935028076,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.781214952468872,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.780189275741577,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.785775899887085,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.78289794921875,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7832376956939697,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.7891666889190674,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.782390832901001,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7840936183929443,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.781845808029175,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.7835659980773926,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.781308174133301,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.778468370437622,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7781128883361816,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7801144123077393,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.7815170288085938,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.782430648803711,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.7829108238220215,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7798941135406494,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.778186082839966,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.7828760147094727,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.7806625366210938,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.78029203414917,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.7755801677703857,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.781352996826172,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.7767527103424072,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.7849977016448975,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.778920888900757,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.782522678375244,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.7826032638549805,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.7874741554260254,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.781752586364746,\n",
       " 'drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.7845940589904785,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.7758753299713135,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.7802910804748535,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.782524585723877,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.781013011932373,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7819929122924805,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7782840728759766,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7802605628967285,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.783663511276245,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.7789809703826904,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.78169322013855,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.777665138244629,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7819747924804688,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7824933528900146,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.785609006881714,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7803122997283936,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.781538724899292,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7825467586517334,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.781205892562866,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.7816202640533447,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.7818377017974854,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.7827398777008057,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.780197858810425,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7817840576171875,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.78330135345459,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7853121757507324,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7820379734039307,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7838168144226074,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.7838821411132812,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.776240825653076,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7803657054901123,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.780090570449829,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7787599563598633,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.778498888015747,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.781546115875244,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.782146453857422,\n",
       " 'drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.783522367477417,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7859132289886475,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.78497314453125,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7820661067962646,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.7835707664489746,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.779137372970581,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7824625968933105,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.781071186065674,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.7818243503570557,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7733547687530518,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.781848192214966,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7814278602600098,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7811412811279297,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.783172845840454,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.7794690132141113,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.782233238220215,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.7805986404418945,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.779399871826172,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7829432487487793,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.7803592681884766,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.7809574604034424,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.781769275665283,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7827131748199463,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.778055191040039,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.7819693088531494,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.783108949661255,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.7862637042999268,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.783041477203369,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.7778472900390625,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.7861621379852295,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.779942512512207,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.7786448001861572,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.783836603164673,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.781949520111084,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.781719923019409,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.782257318496704,\n",
       " 'drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.782623052597046,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.783108711242676,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.7916831970214844,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.7803289890289307,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7793304920196533,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7808291912078857,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7783989906311035,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7853164672851562,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.779910087585449,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.779062271118164,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.776110887527466,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7735517024993896,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7808163166046143,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7815277576446533,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7848711013793945,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7809224128723145,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.7802791595458984,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7825286388397217,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.7894349098205566,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.779843807220459,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.7803146839141846,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.7876737117767334,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7752416133880615,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7800397872924805,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.782031536102295,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.775557279586792,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.777747631072998,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7765402793884277,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.778538942337036,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.7829461097717285,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.779381036758423,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.784820556640625,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7806615829467773,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.7804698944091797,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.7827420234680176,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7835309505462646,\n",
       " 'drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.7850139141082764,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.778055191040039,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7822628021240234,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7841503620147705,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.7817840576171875,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.779186964035034,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.781376600265503,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.7807021141052246,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.7799336910247803,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.77996563911438,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.7809739112854004,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.780491828918457,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7859416007995605,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.784034013748169,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.783419609069824,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.7814910411834717,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.7834548950195312,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.781416177749634,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.777970552444458,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.7798407077789307,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.7851030826568604,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.7821972370147705,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.782870054244995,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.7847390174865723,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.7778007984161377,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.78292179107666,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.7842843532562256,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.778989553451538,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.784658193588257,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.783108949661255,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.7829952239990234,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.784329891204834,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.780298948287964,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.7795441150665283,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.785261631011963,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.780818462371826,\n",
       " 'drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.7811875343322754,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.790602922439575,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.77683687210083,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.7809324264526367,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7791075706481934,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7808632850646973,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7796943187713623,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.780308961868286,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.7818145751953125,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.785024881362915,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.7788243293762207,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7784311771392822,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7846028804779053,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7844605445861816,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7830615043640137,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7854390144348145,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.779303550720215,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7797656059265137,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.781362533569336,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.782874584197998,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.778843641281128,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.7914958000183105,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.77424955368042,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7815606594085693,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.7800145149230957,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7765235900878906,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7847049236297607,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7810444831848145,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.782581329345703,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.7800400257110596,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7847506999969482,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.7808315753936768,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7800772190093994,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.77957820892334,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.779639482498169,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.781167507171631,\n",
       " 'drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.7829864025115967,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7793776988983154,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7807602882385254,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7819182872772217,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.7823445796966553,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.7832529544830322,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7792820930480957,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.7817087173461914,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.7831547260284424,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7844207286834717,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.77880597114563,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7807397842407227,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7814323902130127,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7767701148986816,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.780280113220215,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.7814178466796875,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.7809948921203613,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7821614742279053,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7833423614501953,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.7819302082061768,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.782029151916504,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.781578779220581,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7816648483276367,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.7801270484924316,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.7809336185455322,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.782932758331299,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.782606363296509,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.780712604522705,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.784031629562378,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.783268690109253,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.78143310546875,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.7824645042419434,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.7780838012695312,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.778966188430786,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.7802913188934326,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.7816314697265625,\n",
       " 'drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.779003381729126,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.777236223220825,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.7820420265197754,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.780294179916382,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.77581787109375,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7885282039642334,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.786655902862549,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7784423828125,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.780578374862671,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.7793664932250977,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.779728889465332,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7776689529418945,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.778660535812378,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7784674167633057,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7840771675109863,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7714157104492188,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.7824618816375732,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.779524326324463,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.7768259048461914,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.7775325775146484,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.7895407676696777,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.776113271713257,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7838826179504395,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.785356044769287,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.776195764541626,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7818682193756104,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7813000679016113,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.783827304840088,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.7782247066497803,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.790078639984131,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.778703451156616,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.7830758094787598,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7840735912323,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.779697895050049,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.7769834995269775,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7848598957061768,\n",
       " 'drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.785618782043457,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7806622982025146,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7820208072662354,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.781827449798584,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.7832438945770264,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.779175281524658,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7804105281829834,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.781074285507202,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.782039165496826,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7833564281463623,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.782860517501831,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7819411754608154,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.781163215637207,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7798376083374023,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.781224489212036,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.7829887866973877,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.7798361778259277,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7835733890533447,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7828426361083984,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.783048391342163,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.7817392349243164,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.78110671043396,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7812933921813965,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.778489351272583,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.7819314002990723,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.7795169353485107,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.7838006019592285,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.7819437980651855,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.780758857727051,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.781604051589966,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.781338930130005,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.782195806503296,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.7796740531921387,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.7777810096740723,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.784031391143799,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.7825675010681152,\n",
       " 'drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.780143976211548,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.784735679626465,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.777437925338745,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:9': nan,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7831225395202637,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.784423828125,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7809319496154785,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7845754623413086,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.781304121017456,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.7833704948425293,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:7': 375.8801574707031,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7805063724517822,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7767958641052246,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.781555652618408,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7809629440307617,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7736756801605225,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.781505584716797,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7773096561431885,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.782947063446045,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:9': nan,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:11': nan,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.780766248703003,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 70.13203430175781,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7839174270629883,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.781480550765991,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.788184881210327,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7822787761688232,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.8764359951019287,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.780550956726074,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.7790372371673584,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:7': 210.0933380126953,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:9': 51595.39453125,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:11': nan,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.783525228500366,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.7818338871002197,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7853965759277344,\n",
       " 'drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:11': 2099264000.0,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7831203937530518,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7819108963012695,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.8113346099853516,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.832242488861084,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.8016083240509033,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.8573129177093506,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.783583402633667,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.7824039459228516,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.9971354007720947,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.7844161987304688,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7850358486175537,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.788407564163208,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7906339168548584,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.952179193496704,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 35.225337982177734,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.793124198913574,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.784597158432007,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7933735847473145,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.8232421875,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 12.89266586303711,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.785536527633667,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.782106876373291,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.797729730606079,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.792182445526123,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:5': 4.997341156005859,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.7814817428588867,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.7970974445343018,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.813861131668091,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:5': 4.59050989151001,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.790038824081421,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.7989227771759033,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.795412540435791,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:5': 10.420106887817383,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.786569118499756,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.7829275131225586,\n",
       " 'drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.8184597492218018,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.7821834087371826,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.782289505004883,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.781451463699341,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7824196815490723,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7820818424224854,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.781588554382324,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.782355785369873,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.782466173171997,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.781759262084961,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.7825231552124023,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7826409339904785,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7825348377227783,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7826859951019287,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.78263258934021,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7824416160583496,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.7827205657958984,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7823150157928467,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.7823967933654785,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.7823081016540527,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.78257155418396,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.782413959503174,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7824885845184326,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.782468557357788,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.78255033493042,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7809159755706787,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.781301975250244,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7821590900421143,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.781906843185425,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.7825260162353516,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7824559211730957,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.781982421875,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.782458782196045,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.7821173667907715,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.782292366027832,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.782139778137207,\n",
       " 'drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.782391309738159,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.784795045852661,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:7': 4.253673076629639,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7898011207580566,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.806680679321289,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.7833616733551025,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.788184404373169,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.796314001083374,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.7901721000671387,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7975075244903564,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:7': 5.282479286193848,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7852227687835693,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.8130598068237305,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.799198627471924,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.7851243019104004,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.865455389022827,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.8408775329589844,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7846057415008545,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7957684993743896,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.889223575592041,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.7855072021484375,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.7900471687316895,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.784731864929199,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.825051784515381,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.8306190967559814,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.7860560417175293,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.791902780532837,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.7852110862731934,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.8283629417419434,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:5': 231937.078125,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.78808331489563,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.799341917037964,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.825897216796875,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.7868592739105225,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.7891032695770264,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.7867398262023926,\n",
       " 'drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.8497977256774902,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.782069206237793,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.7825965881347656,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.7823574542999268,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7822823524475098,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7817916870117188,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7825381755828857,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7817232608795166,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.781160354614258,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.78261399269104,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.782776117324829,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.782362222671509,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7822399139404297,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.78218936920166,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7823128700256348,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.782426595687866,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.782316207885742,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7825961112976074,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.782487154006958,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.7821013927459717,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.781463146209717,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.7821156978607178,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7820653915405273,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.782309055328369,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.7819368839263916,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7823054790496826,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7827885150909424,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7824854850769043,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.782557964324951,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.7826783657073975,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7821524143218994,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.782369375228882,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7828316688537598,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.7828164100646973,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.7823398113250732,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7824289798736572,\n",
       " 'drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.7824628353118896,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.783935785293579,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7833075523376465,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.7835631370544434,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.8076584339141846,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.782447099685669,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7835819721221924,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.793189287185669,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.798794746398926,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.7885308265686035,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.8806543350219727,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7838640213012695,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.798341989517212,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7934916019439697,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.814645767211914,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.7899842262268066,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.7849979400634766,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7838034629821777,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7858059406280518,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.8017942905426025,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.788275957107544,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.796264886856079,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7860069274902344,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 5.062045097351074,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.789189577102661,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.7846157550811768,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.814953565597534,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.785757064819336,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.798884391784668,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.876103162765503,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.7868664264678955,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.8707969188690186,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.8819215297698975,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.893320322036743,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.926788806915283,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.7882962226867676,\n",
       " 'drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.800014019012451,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.780578136444092,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.7821831703186035,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.7824745178222656,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7825567722320557,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.782499074935913,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7824299335479736,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.782165050506592,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.782228708267212,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.782205581665039,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.782447576522827,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.782329559326172,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.782447576522827,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.7823598384857178,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7818713188171387,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7824947834014893,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.7823541164398193,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.782526969909668,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.781888723373413,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.7802751064300537,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.7824013233184814,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.781994342803955,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.782114267349243,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.782583713531494,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.782543897628784,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.783066511154175,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.782486915588379,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.78232479095459,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.78249192237854,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.782125234603882,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.782466411590576,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.782215118408203,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7820889949798584,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.782240867614746,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.783268451690674,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7824771404266357,\n",
       " 'drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.782364845275879,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7860188484191895,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:7': 3.7912676334381104,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.784407615661621,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.8092377185821533,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.801884174346924,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7855730056762695,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.7875216007232666,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.82088303565979,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.8238894939422607,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.7937371730804443,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.7851402759552,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7975106239318848,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7846953868865967,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.7834887504577637,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.817594528198242,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.791182041168213,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.7906494140625,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.8036882877349854,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.798949718475342,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.8041789531707764,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.7820959091186523,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 71.18360900878906,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.7871968746185303,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.786041736602783,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.786074638366699,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:7': 4.878616809844971,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:9': 3.790925979614258,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.794733762741089,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:5': 3.7823610305786133,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:7': 3.7876648902893066,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.7885024547576904,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.7871670722961426,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:5': 4.571690082550049,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.8477652072906494,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:9': 3.787534236907959,\n",
       " 'drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.9251811504364014,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.7823286056518555,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.782061815261841,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.782470703125,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7821686267852783,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7824082374572754,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7818620204925537,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.782564401626587,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.7821083068847656,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.7824697494506836,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.782520055770874,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7826426029205322,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7823984622955322,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.780844211578369,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7822988033294678,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.782227039337158,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.7824811935424805,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.782353162765503,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.7826876640319824,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.781933546066284,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.782299041748047,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.782680034637451,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7821996212005615,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7819736003875732,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.7821919918060303,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7834665775299072,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7824642658233643,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7824621200561523,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.7822370529174805,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.780193567276001,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7822022438049316,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.7824618816375732,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.782461404800415,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.781921148300171,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.7823092937469482,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.781848669052124,\n",
       " 'drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.7823705673217773,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:5': 3.7834603786468506,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:7': 6.24417781829834,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:9': 3.790067195892334,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:11': 3.78269624710083,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:5': 3.8234829902648926,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:7': 3.7862813472747803,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:9': 3.7882537841796875,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:11': 3.784966468811035,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:5': 3.786871910095215,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:7': 3.8162319660186768,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:9': 3.8000361919403076,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:11': 3.7870700359344482,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:5': 3.7826590538024902,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:7': 3.7850077152252197,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:9': 3.856360912322998,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:11': 3.78497576713562,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:5': 3.78080677986145,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:7': 3.7849462032318115,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:9': 3.834137439727783,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:11': 3.8177988529205322,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:5': 3.788184881210327,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:7': 3.7886903285980225,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:9': 3.7958738803863525,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:11': 3.8097941875457764,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:5': 3.7816591262817383,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:7': 3.7824156284332275,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:9': 4.200151443481445,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:11': 3.7915725708007812,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:5': 17795.869140625,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:7': 303.6116027832031,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:9': 3.7856688499450684,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:11': 3.829650402069092,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:5': 3.783050775527954,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:7': 3.7867796421051025,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:9': 4.540551662445068,\n",
       " 'drp:False dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:11': 3.782928943634033,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:5': 3.781815767288208,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:7': 3.782701015472412,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:9': 3.7826263904571533,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:11': 3.7821946144104004,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:5': 3.7826104164123535,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:7': 3.7824785709381104,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:9': 3.7817044258117676,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:11': 3.7823145389556885,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:5': 3.7823948860168457,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:7': 3.7826337814331055,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:9': 3.7824461460113525,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:11': 3.7822000980377197,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:5': 3.78242826461792,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:7': 3.7821946144104004,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:9': 3.7814781665802,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:11': 3.782230854034424,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:5': 3.7825353145599365,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:7': 3.7821943759918213,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:9': 3.782325029373169,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:11': 3.7823915481567383,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:5': 3.7826781272888184,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:7': 3.7814900875091553,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:9': 3.7824132442474365,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:11': 3.782442569732666,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:5': 3.7827141284942627,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:7': 3.7826364040374756,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:9': 3.7814109325408936,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:11': 3.7823240756988525,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:5': 3.782240867614746,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:7': 3.7820937633514404,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:9': 3.7820115089416504,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:11': 3.7825193405151367,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:5': 3.7823665142059326,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:7': 3.782352924346924,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:9': 3.7824137210845947,\n",
       " 'drp:False dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:11': 3.7824418544769287}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result, key=result.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7714157104492188"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7819952964782715\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7822320461273193\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:9 3.7823078632354736\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:11 3.7823002338409424\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:5 3.782416820526123\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:7 3.782276153564453\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:9 3.7819480895996094\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:11 3.7824831008911133\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7825324535369873\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:7 3.7825326919555664\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:9 3.782357931137085\n",
      "drp:True dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7826833724975586\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.7824575901031494\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.782639741897583\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.782536506652832\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.7825160026550293\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.782602548599243\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.7824933528900146\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.7824435234069824\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.7820210456848145\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.782402515411377\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.7824792861938477\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.782942771911621\n",
      "drp:True dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.782531499862671\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7816383838653564\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.781348466873169\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.7824289798736572\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.7822022438049316\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.782421112060547\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.7825653553009033\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.782680034637451\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7825098037719727\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.782676935195923\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.782406806945801\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7831170558929443\n",
      "drp:True dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7823362350463867\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:5 3.781714916229248\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7831883430480957\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7839465141296387\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:11 3.7826738357543945\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7814533710479736\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:7 3.784268379211426\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:9 3.782902479171753\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7807154655456543\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:5 3.783813714981079\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:7 3.782475233078003\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:9 3.781811475753784\n",
      "drp:True dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7820653915405273\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.7838551998138428\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.7823901176452637\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.782848596572876\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.783907413482666\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7848877906799316\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7828986644744873\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7809512615203857\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.781832695007324\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.782170295715332\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.782416820526123\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.781412363052368\n",
      "drp:True dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.78255033493042\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.781735897064209\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.7824056148529053\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.782252073287964\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.783801794052124\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.782381772994995\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.7830111980438232\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.781960964202881\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7810959815979004\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.7832181453704834\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.781980037689209\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7823426723480225\n",
      "drp:True dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.781555414199829\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7824208736419678\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7824666500091553\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:9 3.782197952270508\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:11 3.78255295753479\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:5 3.782506227493286\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:7 3.7825114727020264\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:9 3.782547950744629\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:11 3.7822818756103516\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7824606895446777\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:7 3.78244686126709\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:9 3.7825474739074707\n",
      "drp:True dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7825350761413574\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.782477855682373\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7826123237609863\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7822232246398926\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.7828452587127686\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.78246808052063\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.782284736633301\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.782365322113037\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.782850742340088\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.782313585281372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7822988033294678\n",
      "drp:True dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.782039165496826\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.782505750656128\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.782259464263916\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.7824106216430664\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.7825965881347656\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.782266855239868\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.7829315662384033\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.7823874950408936\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7827444076538086\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.7819430828094482\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7826738357543945\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7825045585632324\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7840325832366943\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7837252616882324\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:9 3.784886598587036\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:11 3.7827694416046143\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7826437950134277\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:7 3.7831244468688965\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:9 3.781526565551758\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7816810607910156\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:5 3.7824697494506836\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:7 3.7823290824890137\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7818336486816406\n",
      "drp:True dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7827179431915283\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.782221794128418\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.78385853767395\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.782731056213379\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.7818241119384766\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.783721446990967\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7820820808410645\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7823803424835205\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.783806562423706\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.7811081409454346\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.7804715633392334\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.7811615467071533\n",
      "drp:True dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.7825770378112793\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.782001495361328\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.7818140983581543\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.779999017715454\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.7813827991485596\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.7824227809906006\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.7831690311431885\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7822256088256836\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7815349102020264\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.782130479812622\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.78127384185791\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.782024621963501\n",
      "drp:True dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.782809019088745\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7824785709381104\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:9 3.7825121879577637\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:11 3.782564401626587\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:5 3.7824900150299072\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:7 3.782470226287842\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:9 3.7821669578552246\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:11 3.782445192337036\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7824881076812744\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:7 3.7824835777282715\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:9 3.782740592956543\n",
      "drp:True dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7825026512145996\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.7825303077697754\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7824647426605225\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.782529830932617\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.782482862472534\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.7824933528900146\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.7824528217315674\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.782536506652832\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.7826595306396484\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.7824547290802\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7824642658233643\n",
      "drp:True dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.7825653553009033\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.7825498580932617\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.782496929168701\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.782292127609253\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.782557249069214\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.782437562942505\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.7825045585632324\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.782440423965454\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7823593616485596\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7821433544158936\n",
      "drp:True dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7825472354888916\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7820394039154053\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7821779251098633\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7826104164123535\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:11 3.782857656478882\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7825682163238525\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:7 3.78208327293396\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:9 3.782045364379883\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7825679779052734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:5 3.783845901489258\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:7 3.7831246852874756\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7827236652374268\n",
      "drp:True dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7820732593536377\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.781960964202881\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.7832565307617188\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.781870126724243\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.7832183837890625\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.782318592071533\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7828853130340576\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7826945781707764\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.781118869781494\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.783069133758545\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.7816107273101807\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.7812676429748535\n",
      "drp:True dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.7821381092071533\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7819337844848633\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.7813258171081543\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.7831826210021973\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.782970428466797\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.7843809127807617\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.782771587371826\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7819902896881104\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7837138175964355\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.782261848449707\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.78238844871521\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7823598384857178\n",
      "drp:True dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.7832157611846924\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7824008464813232\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7824108600616455\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:9 3.7825074195861816\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:11 3.7822751998901367\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:5 3.782457113265991\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:7 3.782379388809204\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:9 3.782578468322754\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:11 3.782261848449707\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7823293209075928\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:7 3.7824594974517822\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:9 3.7824745178222656\n",
      "drp:True dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7824130058288574\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.7824714183807373\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7824151515960693\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7825071811676025\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.782240867614746\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.782473564147949\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.7824792861938477\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.7824597358703613\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.782580852508545\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.782480001449585\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.782602548599243\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7823729515075684\n",
      "drp:True dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.7824923992156982\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.782493829727173\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.7824885845184326\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.7824790477752686\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.7826356887817383\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.7824928760528564\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.782482624053955\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.782477617263794\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7827460765838623\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.782404661178589\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7824649810791016\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.782543659210205\n",
      "drp:True dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7823851108551025\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:5 3.783365249633789\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:7 3.781426429748535\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7822203636169434\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:11 3.782062530517578\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7836554050445557\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:7 3.7822678089141846\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:9 3.781599998474121\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:11 3.781764507293701\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:5 3.782498598098755\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:7 3.783163547515869\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7823240756988525\n",
      "drp:True dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7839114665985107\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.7822721004486084\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.7825725078582764\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.7822070121765137\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.783555507659912\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.782552719116211\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7820472717285156\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.782487154006958\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.7828733921051025\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.782437562942505\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.7824132442474365\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.782682180404663\n",
      "drp:True dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.782222032546997\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7819879055023193\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.7828855514526367\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.7826032638549805\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.783250093460083\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.782783031463623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.782637357711792\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7822532653808594\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7817025184631348\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.7821686267852783\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.7821996212005615\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7808613777160645\n",
      "drp:True dropProb:0.7 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.782114028930664\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7824649810791016\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7825708389282227\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:2 nneurons:11 3.7824811935424805\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:5 3.7824807167053223\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:7 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:9 3.7824792861938477\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:4 nneurons:11 3.782479763031006\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7824738025665283\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:7 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:9 3.782480001449585\n",
      "drp:True dropProb:0.9 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7824673652648926\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7824923992156982\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.782470464706421\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.782459259033203\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.7824535369873047\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.782456874847412\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7824788093566895\n",
      "drp:True dropProb:0.9 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.7824668884277344\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.782440662384033\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.7824954986572266\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.782486915588379\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.78244686126709\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7824771404266357\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.782480001449585\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7824878692626953\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7824699878692627\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7823843955993652\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7824792861938477\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:2 nneurons:11 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:5 3.782381772994995\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:7 3.782445192337036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renze\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:9 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:4 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:5 3.782390594482422\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:7 3.782506227493286\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7824416160583496\n",
      "drp:True dropProb:0.9 batch:False optimizer:SGD nlayer:6 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.782471179962158\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.783975601196289\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.7888526916503906\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:2 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7824971675872803\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:7 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:9 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:4 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.782473087310791\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:9 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:RMSprop nlayer:6 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7822911739349365\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:7 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:9 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.809072732925415\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.7824745178222656\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.782501697540283\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:9 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:4 nneurons:11 nan\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.782461643218994\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.7823846340179443\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7824795246124268\n",
      "drp:True dropProb:0.9 batch:False optimizer:ADAM nlayer:6 nneurons:11 nan\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7891011238098145\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:7 3.786381721496582\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:9 3.782426118850708\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:2 nneurons:11 3.7818634510040283\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:5 3.7826645374298096\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:7 3.7847065925598145\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:9 3.8877944946289062\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:4 nneurons:11 3.7882208824157715\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7825024127960205\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:7 4.394413471221924\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:9 3.7838752269744873\n",
      "drp:False dropProb:0.3 batch:True optimizer:SGD nlayer:6 nneurons:11 3.788409471511841\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.8117241859436035\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7944562435150146\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7826273441314697\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.8311030864715576\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.7901511192321777\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.782512664794922\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.782309055328369\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.8153274059295654\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.782555103302002\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.7825160026550293\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.8703322410583496\n",
      "drp:False dropProb:0.3 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.7833991050720215\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7849483489990234\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.782322645187378\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.791870594024658\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.792618751525879\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.7830188274383545\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.8421854972839355\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.9946980476379395\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7872142791748047\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.7823715209960938\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7824647426605225\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7819478511810303\n",
      "drp:False dropProb:0.3 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.785712957382202\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:5 3.782468795776367\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:7 3.782444477081299\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7824809551239014\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:2 nneurons:11 3.782435894012451\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7824575901031494\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:7 3.7826151847839355\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:9 3.782510995864868\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:4 nneurons:11 3.782536029815674\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:7 3.7824783325195312\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:9 3.782480001449585\n",
      "drp:False dropProb:0.3 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7824814319610596\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.782471179962158\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.782487392425537\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.7825067043304443\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.7822964191436768\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7824692726135254\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7824795246124268\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7822518348693848\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.782474994659424\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.7822024822235107\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.7824747562408447\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.7824249267578125\n",
      "drp:False dropProb:0.3 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.7824954986572266\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.782456636428833\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.7824747562408447\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.7824289798736572\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.782475709915161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.782461404800415\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7824816703796387\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7825119495391846\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.7824442386627197\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.7825021743774414\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7824556827545166\n",
      "drp:False dropProb:0.3 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.7824885845184326\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:5 3.7841310501098633\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:7 3.8064756393432617\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:9 3.783399820327759\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:2 nneurons:11 3.789653778076172\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:5 3.8106555938720703\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:7 3.7832374572753906\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:9 3.801983118057251\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:4 nneurons:11 3.790099859237671\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:5 45.559200286865234\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:7 4.932943820953369\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:9 3.783912420272827\n",
      "drp:False dropProb:0.5 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7902345657348633\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.782870054244995\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7921082973480225\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.841850757598877\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.8190951347351074\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.7829222679138184\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.7830557823181152\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.788605213165283\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.787029981613159\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.7852566242218018\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.946068048477173\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.8701984882354736\n",
      "drp:False dropProb:0.5 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.96734881401062\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7828168869018555\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.800795316696167\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.7920591831207275\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.786825656890869\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.783257246017456\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.7837514877319336\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:9 4.417404651641846\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7851028442382812\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:5 8.449256896972656\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:7 4.3430938720703125\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7837982177734375\n",
      "drp:False dropProb:0.5 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.785834789276123\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:7 3.782463550567627\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7824771404266357\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:2 nneurons:11 3.782485008239746\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:7 3.7827463150024414\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:9 3.7825145721435547\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7824652194976807\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:5 3.782505512237549\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:7 3.782508134841919\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:9 3.782487392425537\n",
      "drp:False dropProb:0.5 batch:False optimizer:SGD nlayer:6 nneurons:11 3.7824723720550537\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.782639980316162\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.7824764251708984\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.7825026512145996\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.7824947834014893\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7825140953063965\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.782484292984009\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.782456636428833\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.7824833393096924\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.782449722290039\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.782477378845215\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.782424211502075\n",
      "drp:False dropProb:0.5 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.782496690750122\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.782463550567627\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.782452344894409\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.782482147216797\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.7824532985687256\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.7824959754943848\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.7825326919555664\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7825427055358887\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7824740409851074\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.7824690341949463\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.782494306564331\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.7824833393096924\n",
      "drp:False dropProb:0.5 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.7824721336364746\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:5 3.829232692718506\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:7 4.7498393058776855\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:9 3.784518003463745\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:2 nneurons:11 6.6275954246521\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:5 3.7834088802337646\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:7 3.8059592247009277\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:9 3.8001437187194824\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:4 nneurons:11 3.794545888900757\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7827329635620117\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:7 3.796820640563965\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:9 3.7848308086395264\n",
      "drp:False dropProb:0.6 batch:True optimizer:SGD nlayer:6 nneurons:11 3.7825968265533447\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:5 210.06150817871094\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.790834903717041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.7830698490142822\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.7877037525177\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.782834053039551\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.7841103076934814\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.8018383979797363\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.7845327854156494\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.8266186714172363\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.7831175327301025\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7825467586517334\n",
      "drp:False dropProb:0.6 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.783315420150757\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.7824833393096924\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.8120813369750977\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:9 172.65753173828125\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.783433675765991\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.7827067375183105\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.797198534011841\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.7831287384033203\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.7920076847076416\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.7885100841522217\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.783071279525757\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.7833662033081055\n",
      "drp:False dropProb:0.6 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7879419326782227\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7824792861938477\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7824578285217285\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:9 3.7825205326080322\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:2 nneurons:11 3.782472610473633\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:5 3.7824325561523438\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:7 3.782423973083496\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:9 3.782566547393799\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7823896408081055\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:7 3.7824652194976807\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7824783325195312\n",
      "drp:False dropProb:0.6 batch:False optimizer:SGD nlayer:6 nneurons:11 3.782475471496582\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.782480239868164\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.782416582107544\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.782475471496582\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.782541513442993\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.782513380050659\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7824950218200684\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.7825021743774414\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.7824583053588867\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.782470464706421\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.782670021057129\n",
      "drp:False dropProb:0.6 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.782503128051758\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7824807167053223\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.7823727130889893\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.7824769020080566\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.7824606895446777\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.782504081726074\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:7 3.7824041843414307\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:9 3.7824654579162598\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:4 nneurons:11 3.7824950218200684\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:5 3.7824974060058594\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:7 3.7825534343719482\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:9 3.782475709915161\n",
      "drp:False dropProb:0.6 batch:False optimizer:ADAM nlayer:6 nneurons:11 3.7823448181152344\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:5 16.2379207611084\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:7 3.7821576595306396\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:9 3.7828898429870605\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:2 nneurons:11 3.7819323539733887\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:5 4.0128865242004395\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:7 3.785090684890747\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:9 3.7828567028045654\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:4 nneurons:11 3.938882827758789\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:5 3.7828636169433594\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:7 3.782355308532715\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:9 3.785454750061035\n",
      "drp:False dropProb:0.7 batch:True optimizer:SGD nlayer:6 nneurons:11 3.878826379776001\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:5 3.787957191467285\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:7 3.7829508781433105\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:9 3.784445285797119\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:2 nneurons:11 3.7821242809295654\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:5 3.78635573387146\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:7 3.78216552734375\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:9 3.861692428588867\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:4 nneurons:11 3.7831037044525146\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:5 3.7952589988708496\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:7 3.784287929534912\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:9 3.7951865196228027\n",
      "drp:False dropProb:0.7 batch:True optimizer:RMSprop nlayer:6 nneurons:11 3.782846689224243\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:5 3.78271222114563\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:7 3.782186985015869\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:9 3.783693790435791\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:2 nneurons:11 3.7839155197143555\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:5 3.783336877822876\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:7 3.783935546875\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:9 3.795081615447998\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:4 nneurons:11 3.78952956199646\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:5 3.782076120376587\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:7 3.7828354835510254\n",
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:9 3.791748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drp:False dropProb:0.7 batch:True optimizer:ADAM nlayer:6 nneurons:11 3.7916672229766846\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:5 3.7824950218200684\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:7 3.7826595306396484\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:9 3.782487154006958\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:2 nneurons:11 3.7827911376953125\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:5 3.782479763031006\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:7 3.782474994659424\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:9 3.782458782196045\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:4 nneurons:11 3.7824277877807617\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:7 3.7824811935424805\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:9 3.7824606895446777\n",
      "drp:False dropProb:0.7 batch:False optimizer:SGD nlayer:6 nneurons:11 3.782480478286743\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:5 3.7825043201446533\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:7 3.782515287399292\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:9 3.7825140953063965\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:2 nneurons:11 3.78245210647583\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:5 3.7824795246124268\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:7 3.7824792861938477\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:9 3.7825164794921875\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:4 nneurons:11 3.7825746536254883\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:5 3.782482147216797\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:7 3.782475233078003\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:9 3.7824819087982178\n",
      "drp:False dropProb:0.7 batch:False optimizer:RMSprop nlayer:6 nneurons:11 3.7825896739959717\n",
      "drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:5 3.7824316024780273\n",
      "drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:7 3.782447099685669\n",
      "drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:9 3.7825067043304443\n",
      "drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:2 nneurons:11 3.782486915588379\n",
      "drp:False dropProb:0.7 batch:False optimizer:ADAM nlayer:4 nneurons:5 3.782480239868164\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'drp_ls': [True, False],\n",
    "             'drpProb_ls': [0.3, 0.5 ,0.6, 0.7, 0.9],\n",
    "             'batch_ls': [True, False],\n",
    "             'optimizer_ls': ['SGD', 'RMSprop', 'ADAM'],\n",
    "             'layer_ls': [2,4,6],\n",
    "              'neuron_ls': [5,7,9,11]}\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.02\n",
    "n_epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "result = {}\n",
    "result2 = {}\n",
    "for drp in param_dist['drp_ls']:\n",
    "    for drpProb in param_dist['drpProb_ls']:\n",
    "        for batch in param_dist['batch_ls']:\n",
    "            for optimizer in param_dist['optimizer_ls']:\n",
    "                for nlayer in param_dist['layer_ls']:\n",
    "                    for nneurons in param_dist['neuron_ls']:\n",
    "                        ls = [nneurons]*nlayers\n",
    "                        ls = np.insert(ls, 0, Xcv1.shape[1]).tolist()\n",
    "                        ls.append(1)\n",
    "                        nnt, err = npy.nnTrain(Xtrain1, Ytrain1, ls, drp, drpProb, batch, opt, learning_rate, n_epochs) \n",
    "                        string = 'drp:' + str(drp) + ' dropProb:' + str(drpProb) + ' batch:' + str(batch)\\\n",
    "                        + ' optimizer:' + str(optimizer) + ' nlayer:' + str(nlayer) + ' nneurons:' + str(nneurons)\n",
    "                        result[string]  = npy.nnTest(nnt, Xcv1, Ycv1) \n",
    "                        result2[string] = err\n",
    "                        if sum(np.array(err)>20) == 0:\n",
    "                            plt.plot(err)\n",
    "                        print(string, result[string])\n",
    "\n",
    "plt.xlabel('Reps')\n",
    "plt.ylabel('Losses')\n",
    "plt.title('Computed train losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
